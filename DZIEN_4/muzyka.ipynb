{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y78INFJGASQV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja do ekstrakcji mel-spektrogramu\n",
        "def extract_features(file_path, n_mfcc=40, max_len=130):\n",
        "    audio, sr = librosa.load(file_path, duration=30)\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "    if mfcc.shape[1] < max_len:\n",
        "        pad_width = max_len - mfcc.shape[1]\n",
        "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    else:\n",
        "        mfcc = mfcc[:, :max_len]\n",
        "    return mfcc"
      ],
      "metadata": {
        "id": "PbsoB97iAYUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URL do zbioru danych GTZAN\n",
        "url = \"http://opihi.cs.uvic.ca/sound/genres.tar.gz\"\n",
        "\n",
        "# Pobierz plik tar.gz\n",
        "try:\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "    # Extract the archive\n",
        "    z = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "    z.extractall(\"/content/gtzan\") # Extract to /content/gtzan\n",
        "\n",
        "    print(\"Dataset downloaded and extracted successfully.\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading dataset: {e}\")\n",
        "except zipfile.BadZipFile as e:\n",
        "    print(f\"Error extracting dataset: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKFp2VskBuAb",
        "outputId": "b8508037-3661-4b71-8cdb-2a4cc901b06f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading dataset: HTTPConnectionPool(host='opihi.cs.uvic.ca', port=80): Max retries exceeded with url: /sound/genres.tar.gz (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fd611d98250>, 'Connection to opihi.cs.uvic.ca timed out. (connect timeout=None)'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ścieżka do pobranego zbioru danych\n",
        "data_path = \"/content/gtzan/genres\"\n",
        "\n",
        "# Lista gatunków muzycznych\n",
        "genres = os.listdir(data_path)\n",
        "\n",
        "# Inicjalizacja pustych list do przechowywania cech i etykiet\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "# Ekstrakcja cech z plików audio\n",
        "for genre in genres:\n",
        "    genre_path = os.path.join(data_path, genre)\n",
        "    for file in os.listdir(genre_path):\n",
        "        file_path = os.path.join(genre_path, file)\n",
        "        mfcc = extract_features(file_path)\n",
        "        features.append(mfcc)\n",
        "        labels.append(genre)\n",
        "\n",
        "# Konwersja do tablic numpy\n",
        "features = np.array(features)\n",
        "labels = np.array(labels)\n",
        "\n",
        "\n",
        "# Normalizacja danych\n",
        "scaler = StandardScaler()\n",
        "features = scaler.fit_transform(features.reshape(-1, features.shape[-1])).reshape(features.shape)\n",
        "\n",
        "# Kodowanie etykiet\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Podział na zbiory treningowy i testowy\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Dodanie wymiaru kanałów dla CNN\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]\n",
        "\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "rnq7mvmECUkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Konwersja danych do tablic numpy\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Normalizacja danych\n",
        "data = data / np.max(data)\n",
        "\n",
        "# Kodowanie etykiet\n",
        "encoder = LabelEncoder()\n",
        "encoded_labels = encoder.fit_transform(labels)\n",
        "\n",
        "# Rozdzielenie danych na zestaw treningowy i testowy\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Dodanie wymiaru kanałów (dla CNN)\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "L3ny09d7AZM_",
        "outputId": "8dc88f94-d46e-49ea-bc22-40522a6c6933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path_to_gtzan_dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7139bdedce91>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Przygotowanie danych\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgenres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_gtzan_dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Budowa modelu CNN\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(40, 130, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(genres), activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilacja modelu\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QRppPPlQBO7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trenowanie modelu\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "hegX6zqrBdry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ocena modelu\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "id": "ogaxLgpvBg9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wykresy dokładności i strat\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V9-qJ2BdBnp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja do generowania i wyświetlania spektrogramu\n",
        "def plot_spectrogram(file_path, title):\n",
        "    audio, sr = librosa.load(file_path, duration=30)\n",
        "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128, fmax=8000)\n",
        "    log_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(log_spectrogram, sr=sr, x_axis='time', y_axis='mel', fmax=8000, cmap='coolwarm')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Przykładowe pliki do wyświetlenia spektrogramów\n",
        "example_files = [\n",
        "    os.path.join(DATA_PATH, genres[0], os.listdir(os.path.join(DATA_PATH, genres[0]))[0]),\n",
        "    os.path.join(DATA_PATH, genres[1], os.listdir(os.path.join(DATA_PATH, genres[1]))[0])\n",
        "]\n",
        "\n",
        "# Wyświetlenie spektrogramów\n",
        "plot_spectrogram(example_files[0], f\"Spectrogram: {genres[0]}\")\n",
        "plot_spectrogram(example_files[1], f\"Spectrogram: {genres[1]}\")\n"
      ],
      "metadata": {
        "id": "LaLHAAAYBqaV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
